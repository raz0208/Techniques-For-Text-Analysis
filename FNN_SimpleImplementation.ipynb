{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOL48/ErCn/FdfGYwcy12u2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/raz0208/Techniques-For-Text-Analysis/blob/main/FNN_SimpleImplementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feedforward Neural Network (FNN)\n",
        "A Feedforward Neural Network (FNN) is one of the simplest and most widely used types of artificial neural networks. It’s called \"feedforward\" because the data flows in one direction — from input to output — without any loops or cycles.\n",
        "\n",
        "Here’s a quick breakdown of how it works:\n",
        "- **Input Layer:** Takes in the input features (like images, text, or numerical data).\n",
        "- **Hidden Layers:** One or more layers of neurons that process the input by applying weights, biases, and activation functions.\n",
        "- **Output Layer:** Produces the final prediction or classification.\n",
        "\n",
        "In an FNN, each neuron in one layer is connected to every neuron in the next layer — that’s why it’s often called a fully connected network. The network is trained using backpropagation, adjusting weights based on the error between predicted and actual outputs."
      ],
      "metadata": {
        "id": "Z8uz-3G_jr-x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1: Import libraries and read data"
      ],
      "metadata": {
        "id": "-J9c3YWXk6kY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "A0H-N6aOjptF"
      },
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read data (Dummy data for illustration)\n",
        "data = [\n",
        "    (\"hello world\", 0),\n",
        "    (\"machine learning is amazing\", 1),\n",
        "    (\"deep learning for vision\", 1),\n",
        "    (\"hello from the other side\", 0),\n",
        "]\n",
        "\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ipMCyQuilTVK",
        "outputId": "01f71b10-2a89-4b82-ce1e-8372ff20d31d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('hello world', 0),\n",
              " ('machine learning is amazing', 1),\n",
              " ('deep learning for vision', 1),\n",
              " ('hello from the other side', 0)]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2: Process data"
      ],
      "metadata": {
        "id": "zPFsidvclgkI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize and build vocabulary\n",
        "tokens = [word for text, _ in data for word in text.split()]\n",
        "vocab = {word: idx for idx, (word, _) in enumerate(Counter(tokens).items())}\n",
        "\n",
        "print(tokens, \"\\n\")\n",
        "print(vocab, \"\\n\")\n",
        "\n",
        "# Indexing\n",
        "def encode(text):\n",
        "    return [vocab[word] for word in text.split() if word in vocab]\n",
        "\n",
        "encoded_data = [(encode(text), label) for text, label in data]\n",
        "\n",
        "print(encoded_data, \"\\n\")\n",
        "\n",
        "# Padding sequences and creating tensors\n",
        "max_len = max(len(x) for x, _ in encoded_data)\n",
        "X = torch.tensor([x + [0] * (max_len - len(x)) for x, _ in encoded_data])\n",
        "y = torch.tensor([label for _, label in encoded_data])\n",
        "\n",
        "X,y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhM8hPovlf-w",
        "outputId": "04b948d8-82af-492a-eebf-c8e997fafdde"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['hello', 'world', 'machine', 'learning', 'is', 'amazing', 'deep', 'learning', 'for', 'vision', 'hello', 'from', 'the', 'other', 'side'] \n",
            "\n",
            "{'hello': 0, 'world': 1, 'machine': 2, 'learning': 3, 'is': 4, 'amazing': 5, 'deep': 6, 'for': 7, 'vision': 8, 'from': 9, 'the': 10, 'other': 11, 'side': 12} \n",
            "\n",
            "[([0, 1], 0), ([2, 3, 4, 5], 1), ([6, 3, 7, 8], 1), ([0, 9, 10, 11, 12], 0)] \n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 0,  1,  0,  0,  0],\n",
              "         [ 2,  3,  4,  5,  0],\n",
              "         [ 6,  3,  7,  8,  0],\n",
              "         [ 0,  9, 10, 11, 12]]),\n",
              " tensor([0, 1, 1, 0]))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3: Define models\n",
        "- Linear Model\n",
        "- Non linear Model"
      ],
      "metadata": {
        "id": "ff74yaCNmXAx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
        "\n",
        "# Linear FNN\n",
        "class LinearFNN(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(LinearFNN, self).__init__()\n",
        "        self.fc = nn.Linear(input_size, 1)\n",
        "    def forward(self, x):\n",
        "        return torch.sigmoid(self.fc(x.float())).squeeze()\n",
        "\n",
        "# Non-linear FNN\n",
        "class NonLinearFNN(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(NonLinearFNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, 16)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(16, 1)\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.fc1(x.float()))\n",
        "        return torch.sigmoid(self.fc2(x)).squeeze()"
      ],
      "metadata": {
        "id": "I_Sr1BW7mVD5"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 4: Define training and testing\n",
        "- Training and testing linear model\n",
        "- Traninf and testing nonlinear model"
      ],
      "metadata": {
        "id": "2_GkRmPgmk3A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Class and function to train FNN\n",
        "class Trainer:\n",
        "    def __init__(self, model, lr=0.001):\n",
        "        self.model = model\n",
        "        self.criterion = nn.BCELoss()\n",
        "        self.optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    def train(self, X, y, epochs=10):\n",
        "        for epoch in range(epochs):\n",
        "            self.optimizer.zero_grad()\n",
        "            outputs = self.model(X)\n",
        "            loss = self.criterion(outputs, y.float())\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "            print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "    def evaluate(self, X, y):\n",
        "        with torch.no_grad():\n",
        "            outputs = self.model(X)\n",
        "            predictions = (outputs > 0.5).int()\n",
        "            predictions = predictions.view(-1).cpu().numpy()  # Ensure 1D array\n",
        "            y = y.view(-1).cpu().numpy()  # Ensure 1D array\n",
        "            acc = accuracy_score(y, predictions)\n",
        "            print(f\"Accuracy: {acc:.4f}\")"
      ],
      "metadata": {
        "id": "a-FYdgjfmjaw"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 5: Train and test models"
      ],
      "metadata": {
        "id": "rss-5_BEm8hK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and test the model\n",
        "input_size = max_len\n",
        "\n",
        "print(\"Training Linear Model:\")\n",
        "linear_model = LinearFNN(input_size)\n",
        "trainer = Trainer(linear_model)\n",
        "trainer.train(X_train, y_train)\n",
        "trainer.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vHjSaa3Nm6lo",
        "outputId": "080b53cf-2057-499e-dc1b-522ad0140bcd"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Linear Model:\n",
            "Epoch 1, Loss: 1.9917\n",
            "Epoch 2, Loss: 1.9835\n",
            "Epoch 3, Loss: 1.9752\n",
            "Epoch 4, Loss: 1.9670\n",
            "Epoch 5, Loss: 1.9588\n",
            "Epoch 6, Loss: 1.9506\n",
            "Epoch 7, Loss: 1.9425\n",
            "Epoch 8, Loss: 1.9343\n",
            "Epoch 9, Loss: 1.9261\n",
            "Epoch 10, Loss: 1.9180\n",
            "Accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nTraining Non-Linear Model:\")\n",
        "non_linear_model = NonLinearFNN(input_size)\n",
        "trainer = Trainer(non_linear_model)\n",
        "trainer.train(X_train, y_train)\n",
        "trainer.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDEbM66mm_Lo",
        "outputId": "3a643e2f-1aae-4bfe-dff5-e8bed13e2054"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training Non-Linear Model:\n",
            "Epoch 1, Loss: 1.3077\n",
            "Epoch 2, Loss: 1.2796\n",
            "Epoch 3, Loss: 1.2518\n",
            "Epoch 4, Loss: 1.2245\n",
            "Epoch 5, Loss: 1.1978\n",
            "Epoch 6, Loss: 1.1715\n",
            "Epoch 7, Loss: 1.1456\n",
            "Epoch 8, Loss: 1.1202\n",
            "Epoch 9, Loss: 1.0954\n",
            "Epoch 10, Loss: 1.0712\n",
            "Accuracy: 1.0000\n"
          ]
        }
      ]
    }
  ]
}