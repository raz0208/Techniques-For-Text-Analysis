{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOobZBT4A5/1NrjT4EMvBgL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/raz0208/Techniques-For-Text-Analysis/blob/main/Retrieval_Augmented_Generation(RAG).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Retrieval-Augmented Generation (RAG):\n"
      ],
      "metadata": {
        "id": "6ECAp5GkfMbe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Process:\n",
        "1. Import libraries\n",
        "2. Setup OpenAI API key\n",
        "3. Download and load data\n",
        "4. Split text to small chunk\n",
        "5. Load pretrained best model for embedding\n",
        "6. Convert text chunk into embedding\n",
        "7. Store chunk + embedding into Lance DB\n",
        "8. Convert user question into embedding\n",
        "9. Retrieve top 5 most relevant text chunk\n",
        "10. Format prompt with context citation\n",
        "11. Sent to GPT-4 for answering the question\n",
        "\n"
      ],
      "metadata": {
        "id": "DokL3mT7fOZc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Djs5PwV-fHCn"
      },
      "outputs": [],
      "source": []
    }
  ]
}